{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Inception_V3",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27F7x2X6bd9m",
        "colab_type": "text"
      },
      "source": [
        "# Connect with Google Drive for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib8IU6kLapd1",
        "colab_type": "code",
        "outputId": "9f16f3db-559c-4b80-bd17-3282316a3137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grdgTB5bblRD",
        "colab_type": "code",
        "outputId": "e8b34023-00ed-45e9-f7a5-7870ffd6d2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os \n",
        "\n",
        "print(os.getcwd())\n",
        "print(os.listdir())\n",
        "\n",
        "os.chdir('drive/My Drive/Projects/Dog Breed 2.0/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3aw6L_LgD2F",
        "colab_type": "text"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRpGB_DSbz9M",
        "colab_type": "code",
        "outputId": "f9092333-cdc9-41d0-95ed-f326c7b71cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras import regularizers\n",
        "import tensorflow.keras as keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Lambda, GlobalAveragePooling2D\n",
        "from keras.layers.core import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Li52qfyJpsb",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeIx3F5Cbuvz",
        "colab_type": "code",
        "outputId": "47a2b986-5a97-4952-971e-780fb2e7bb78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_path = 'dataset/without_downsampled_data/train/'\n",
        "cls_ = os.listdir(train_path)\n",
        "no_cls = len(os.listdir(train_path))\n",
        "\n",
        "img_height = 229\n",
        "img_width = 229\n",
        "batch_size = 128\n",
        "epoch = 100\n",
        "model_name = \"inceptionV3_KaggelDataset_WithoutDownsampled_Droupout0_LrNONE_.h5\"\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   validation_split=0.1)\n",
        "\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "                                                train_path, \n",
        "                                                target_size=(img_height, img_width),\n",
        "                                                classes=cls_, \n",
        "                                                batch_size=batch_size,\n",
        "                                                subset='training')\n",
        "\n",
        "\n",
        "validation_batches = train_datagen.flow_from_directory(\n",
        "                                                    train_path,\n",
        "                                                    target_size=(img_height, img_width),\n",
        "                                                    classes=cls_,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    subset='validation')\n",
        "\n",
        "\n",
        "counter = Counter(train_batches.classes)\n",
        "max_value = float(max(counter.values()))\n",
        "\n",
        "\n",
        "CLASS_WEIGHTS = {classid: max_value / num_occurences\n",
        "                 for classid, num_occurences in counter.items()}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7451 images belonging to 120 classes.\n",
            "Found 770 images belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olya8GI0H6I7",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9nwwL6BArAM",
        "colab_type": "code",
        "outputId": "df59c955-3e24-4918-97fb-19646b4b481f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "\n",
        "# enable if required\n",
        "# model.add(Dense(1024, activation='relu', kernel_regularizer = regularizers.l2(0.0001), \n",
        "#                                     activity_regularizer = regularizers.l1(0.0001)))\n",
        "#model.add(Dropout(0.20))\n",
        "model.add(Dense(no_cls, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 14:04:03.281349 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0730 14:04:03.343427 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 14:04:03.353987 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0730 14:04:03.392703 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0730 14:04:03.394120 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0730 14:04:06.324262 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0730 14:04:06.715913 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0730 14:04:07.501477 139779522197376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho61boMRFcLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model Compiled Successfully\")\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint('Outputs/keras/'+ model_name,\n",
        "                                  monitor='val_acc',\n",
        "                                  mode='max',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True)\n",
        "\n",
        "\n",
        "lr_callback = ReduceLROnPlateau(min_lr=0.000001)\n",
        "\n",
        "\n",
        "callback_list = [modelcheckpoint, lr_callback]\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_batches, steps_per_epoch = train_batches.samples // batch_size,\n",
        "    validation_data=validation_batches, validation_steps = validation_batches.samples // batch_size,\n",
        "    epochs=epoch, verbose=1, \n",
        "    callbacks = callback_list,\n",
        "    class_weight = CLASS_WEIGHTS,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uYDlpKnLV43",
        "colab_type": "text"
      },
      "source": [
        "# Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7DPOkkyLUi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import History\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
